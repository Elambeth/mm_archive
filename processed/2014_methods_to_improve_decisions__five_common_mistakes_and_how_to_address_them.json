{
  "filename": "2014_methods_to_improve_decisions__five_common_mistakes_and_how_to_address_them.pdf",
  "metadata": {
    "format": "PDF 1.6",
    "title": "",
    "author": "",
    "subject": "",
    "keywords": "",
    "creator": "",
    "producer": "www.ilovepdf.com",
    "creationDate": "D:20240423223435-07'00'",
    "modDate": "D:20240423223541-07'00'",
    "trapped": "",
    "encryption": null
  },
  "pages": [
    {
      "number": 1,
      "text": " \n \nFOR DISCLOSURES AND OTHER IMPORTANT INFORMATION, PLEASE REFER TO THE BACK OF THIS REPORT. \nFebruary 24, 2014 \n \nAuthors \nMichael J. Mauboussin \nmichael.mauboussin@credit-suisse.com \nDan Callahan, CFA \ndaniel.callahan@credit-suisse.com \n \n \n\u201cYou gain more by not being stupid than you do by being smart. Smart gets \nneutralized by other smart people. Stupid does not.\u201d \n \nPhil Birnbaum1 \n \n \uf402\n This report covers five common mistakes that investment firms make and \noffers practical guidance on how to manage each of them.  \n \n \n \n \n \n \n \nMistake  \nSolution\n1. Relying too much on the \u201cinside view.\u201d\nIntegrate the \u201coutside view.\u201d\n2. Failure to consider a sufficient range of \nalternatives.\nConduct a premortem.\n3. Underestimating or underappreciating \nan opposing point of view.\nCreate a team to challenge your mind-set.\n4. Not imposing self-accountability.\nMaintain a decision-making journal. \n5. Creating an environment that is not \nconducive to good decisions.\nBe mindful of your surroundings and work \nto improve them. \nGLOBAL FINANCIAL STRATEGIES \nwww.credit-suisse.com \nMethods to Improve Decisions \nFive Common Mistakes and How to Address Them  \n"
    },
    {
      "number": 2,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n2 \nIntroduction \n \nIn his wonderful book, The Checklist Manifesto, Atul Gawande, a surgeon at Brigham and Women\u2019s Hospital \nin Boston, explains the value of using a checklist to improve outcomes in a wide range of fields including \nmedicine, aviation, construction, and investing. The power of a checklist is not that it improves your skill, but \nrather that it makes sure you apply your skill consistently. \n \nGawande interviews an investor who uses a checklist to improve his investment process. This investor believes \nhe can reliably beat the market, encouraged by the experience of those in other fields who have seen \nremarkable improvements in results by adhering to a checklist. He notes, \u201c. . . they improve their outcomes \nwith no increase in skill. That\u2019s what we\u2019re doing when we use a checklist.\u201d2  \n \nOne of the most common questions we hear from investors is: \u201cHow do I improve my decision-making \nprocess?\u201d Most investors have a process\u2014some are more formalized than others\u2014and poor outcomes are \nfrequently the result of deviating from that process either consciously or unconsciously. A checklist is valuable \nprecisely because it compels you to hew to your process. \n   \nIn his well-known essay, \u201cThe Loser\u2019s Game,\u201d Charles Ellis describes research by Simon Ramo on the game \nof tennis.3 Ramo, who is now 100 years old and appears to be going strong, has a PhD in physics from the \nCalifornia Institute of Technology and is the \u201cR\u201d of the old TRW Inc. His study of tennis, published in a book \ncalled Extraordinary Tennis for the Ordinary Player, revealed that the sport is really two games with one name. \nIn pro tennis, the players win 80 percent of the points through superior skill. In ordinary tennis, the players lose \n80 percent of the points by making mistakes.  \n \nRamo\u2019s prescription for winning in ordinary tennis, the variety most of us play, is to simply make fewer errors \nthan your opponent does. Instead of trying for a brilliant shot, just return the ball methodically and let your \nopponent err. He writes, \u201cOrdinary tennis consists in large part of a wide assortment of errors that can be \ngloriously and exclusively claimed by the person who committed them.\u201d4 Ellis makes a similar point about other \ncompetitive endeavors such as warfare and golf.5  \n \nMarkets are different from sports in that you are competing not against another individual or team but rather \nagainst the collective wisdom, or madness, of the crowd. But the main lesson remains: It\u2019s often easier to \nsucceed by making fewer mistakes than it is by being more brilliant.       \n \nThis report covers five common mistakes and offers concrete and actionable ways to manage them. You can \nthink of these mistakes as the common reasons that investors veer from their investment process or cases \nwhere the processes themselves are incomplete. \n \nMistake #1: Relying too much on the \u201cinside view.\u201d \nSolution: Integrate the \u201coutside view.\u201d \n \nThe results of an experiment by Roger Buehler, a professor of psychology, will come as no surprise to you if \nyou have kids in school. Buehler asked college students to tell him the date by which they were 99 percent \nconfident they would have completed a school assignment. For example, if he asked on a Monday, the \nstudents might respond that they were nearly certain to be done with their academic project by Friday.6   \n \nWhen Buehler checked on the predictions, he found that only 45 percent of the students had completed the \ntasks on the designated date. The students had confidence in their estimates that vastly surpassed their \n"
    },
    {
      "number": 3,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n3 \naccomplishments. This tendency to be overly optimistic happens in many settings, from judging how long it will \ntake to remodel your kitchen to estimating the launch date for a new product to forecasting the cost of an \ninfrastructure project.7  \n \nThere is a natural way of thinking about plans and predictions, which psychologists call the \u201cinside view.\u201d We \ngather lots of information, consider the specifics of the situation, and combine the two to create a scenario for \nthe future. For instance, a student might consider how busy she is in the upcoming days, assess the difficulty \nof the assignment, and then figure that it\u2019s almost a sure thing that she\u2019ll have it done by Friday.   \n \nBut there\u2019s another way to think about plans and predictions that doesn\u2019t come naturally to us but is more \nrobust. Psychologists call this the \u201coutside view.\u201d8 The outside view considers the problem as an instance of a \nlarger reference class. Basically, the outside view imposes a fundamental question: \u201cWhat happened when \nothers were in this position before?\u201d  \n \nResearch shows that the inside view often yields predictions that are too optimistic, revealing a form of \noverconfidence. The outside view generally tempers that overconfidence and provides a much stronger \nfoundation for thinking about how the future might unfold.  \n \nAs a case in point, scientists asked venture capitalists (VCs) to describe a transaction they were working on, \nincluding an estimate of the expected rate of return. The average expected return was about 30 percent. The \nresearchers then asked the VCs to consider two other deals that they deemed comparable. The rate of return \nfor those deals was 20 percent. After having exposed the VCs to the outside view, albeit a small sliver of the \ntotal number of deals, 80 percent of the VCs revised down the expected rate of return for the focal deal.9   \n   \nThe contrast between the inside and outside view is a good way to frame the debate about intuition and \nstatistics. Intuition works very well in a narrow number of domains, but people tend to rely on their intuition in \ncases where the statistics yield much better insight. When given a choice, start with statistics and then allow \nyour intuition a say. Daniel Kahneman, a psychologist who won the Nobel Prize in economics, calls this \n\u201cdisciplined intuition.\u201d If you start with intuition and then turn to statistics, you will likely select the data that \nmakes your case. \n \nPsychologists have blamed overconfidence for lots of bad outcomes, including wars, strikes, and stock market \nbubbles. But according to one theory there are three varieties of overconfidence that derive from distinct \nmental mechanisms. The variety of overconfidence that is relevant here is \u201coverprecision,\u201d defined as \u201can \nexcessive certainty regarding the accuracy of one\u2019s beliefs.\u201d10 The outside view foils overprecision by \ncompelling the decision maker to consider a range of outcomes consistent with the problem.    \n  \nSimulations can also enhance the input from the outside view. Say the value of a particular company is \nsensitive to the price of a commodity. A simulator, loaded with a sensible distribution of prices for that \ncommodity, can then generate a range of possible values for the company. The exercise is useful precisely \nbecause the simulator has no intuition about how the values should come out. \n \nDaniel Kahneman and his collaborator for much of his pioneering work, Amos Tversky, offer a number of \nsteps to institute the outside view:11 \n \n1. Choose an appropriate reference class. The goal is to find a reference class that is large enough to \nbe statistically useful but sufficiently narrow to be applicable to the decision you face. In the world of \ninvesting and corporate performance, there is a rich amount of reference class data. Take patterns in \nreturn on invested capital (ROIC) as an example. If you know a company\u2019s current ROIC, you can \n"
    },
    {
      "number": 4,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n4 \nexamine the trajectory of results for companies in a similar position.12 Another illustration is mergers and \nacquisitions (M&A) for companies. There are a lot of data on M&A, and what leads to value creation \n(cash deals at modest premiums with substantial synergies) and value destruction (stock deals at large \npremiums with modest synergies).  \n \n2. Assess the distribution of outcomes. Not all outcomes follow a normal, bell-shaped distribution. For \nexample, of the roughly 2,900 initial public offerings (IPOs) in technology since 1980, a small fraction of \nthe companies have created the vast preponderance of the value. So while this is a relevant reference \nclass, the outcomes are heavily skewed. This renders the conventional notion of average or standard \ndeviation meaningless. Other distributions are not as wild and can provide very robust guidelines for \nforecasting. \n \n3. Make a prediction. With data from the reference class and knowledge of the distribution, make an \nestimate. At this juncture you should be ready to consider a range of probabilities and outcomes. Let\u2019s \nsay you want to make a point estimate for the total shareholder return for the S&P 500 Index in 2014, \nsomething dozens of strategists actually do. Your forecast would appeal to the reference class, which is \nthe past results for S&P 500 returns, and would examine the shape of the distribution of those returns. \nYou could also consider valuation, which might lead to a forecast of returns that are below or above the \nhistorical average. \n \n4. Assess the reliability of your prediction and adjust as appropriate. This last step is a crucial one, \nas it takes into account how much you should regress your estimate toward the average. Statisticians \nhave a term they call \u201creliability,\u201d which measures the correlation of the same metric over different periods \nof time. In cases where correlation is low, indicating low reliability, it is appropriate to regress your \nestimate to the mean substantially. Since the correlation of the returns for the S&P 500 is close to zero \nfrom year to year, any forecast of the S&P 500 for a single year should be close to the historical average. \n \nFinding an appropriate reference class and integrating it into a forecast is not always easy, and researchers \nhave given considerable attention to how to do it most effectively.13 But you are more likely to make a mistake \nby ignoring the outside view than you are by misusing it.  \n \nIn his latest book, Left Brain, Right Stuff, Phil Rosenzweig, a professor at IMD, makes a point worth \nconsidering. For some decisions, you can have no influence on the outcome. If you flip a coin and call heads, \nthe coin will land on one side or the other without regard for your prediction. In the cases where the decision \nmaker can influence the outcome, Rosenzweig argues that optimism may lead to better performance.14   \n \nExecutives and investors generally think by analogy, searching their mental databases for prior cases that \nappear similar and, hence, instructive. This is the basis for the case study approach. Humans are very good at \nplacing items in categories, and categories facilitate inductive reasoning. For instance, the statement, \u201cRabbits \nhave Property X; therefore, Squirrels have Property X,\u201d is a stronger argument than, \u201cRabbits have Property \nX; therefore, Goldfish have Property X,\u201d because it is more natural to place rabbits and squirrels in the same \ncategory than it is to place rabbits and goldfish together.15 \n \nYet reliance on case studies can be perilous for at least two reasons. First, research shows that when we look \nfor similarities in two items that we compare, we see similarities. But when we look for differences, we see \ndifferences.   \n \nIn the 1970s, Amos Tversky asked subjects which pair of countries they deemed more similar, West Germany \nand East Germany or Nepal and Ceylon (which changed its name to Sri Lanka in 1972). Two-thirds of the \n"
    },
    {
      "number": 5,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n5 \nsubjects selected West Germany and East Germany. Tversky then asked subjects which pair of countries they \ndeemed more different. Logic suggests an answer that is the complement of the first response, hence two-\nthirds finding Nepal and Ceylon more different. But that\u2019s not what Tversky found. Seventy percent of the \nsubjects rated West Germany and East Germany more different than the other pair. What you are looking for \ndictates what you see.16    \n \nSecond, our natural tendency to rely on categorization to reason inductively leads to a focus on attributes as \nopposed to circumstances. Attributes are features that allow for categorization. For instance, animals with \nwings and feathers can fly. Circumstances capture causal mechanisms. Since the physics of lift causes flight, \nanimals or objects that can create lift will fly, including most birds and airplanes, and those that can\u2019t create lift \nwon\u2019t fly. To learn from history, you need to understand causality.17    \n \nMistake #2: Failure to consider a sufficient range of alternatives. \nSolution: Conduct a premortem. \n \nMost people are familiar with a postmortem, where doctors try to learn from the mistakes that led to a \npatient\u2019s death. This technique seeks to learn from the past. The \u201cpremortem,\u201d popularized by a psychologist \nnamed Gary Klein, is another technique that sharpens our decision making. Rather than using the past as a \nguide for the present, the premortem goes from the future to the present. This is a technique called \n\u201cprospective hindsight.\u201d18  \n \nHere\u2019s the idea. Before you actually make a decision, launch yourself into the future, say one year from now, \nand pretend that you made the decision. Now assume the decision turned out poorly, and you must document \nthe reasons for the failure. Prospective hindsight places you ahead in time and grants you the knowledge of \nthe bad result. You can then think carefully about what went awry. This process taps into our natural facility to \nexplain events for known outcomes. \n \nJay Russo and Paul Schoemaker, leading researchers on decision making, provide an example of how this \nprocess works.19 Answer the following question: \n \nHow likely is it that a woman will be elected the leader of your country in the first election after the next one? \nThink about all the reasons why this might happen. For specificity, provide a numerical probability. \n \nNow consider another version of the question, which uses prospective hindsight: \n \nImagine that the first election after the next one has occurred and a woman has been elected the leader of \nyour country. Think about all the reasons why this might have happened. Then provide a numerical probability \nof this actually occurring. \n \nRusso and Schoemaker find that the second version of the question generates a greater number of paths to \nthe event, as well as a higher probability, than the first one. For instance, in one version of an experiment, they \nfound that the subjects who used prospective hindsight generated 25 percent more reasons than those who \ndid not use the technique. In addition, the reasons were more specific and more closely aligned with the \nscenario the subjects considered.    \n \n \n \n \n"
    },
    {
      "number": 6,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n6 \nGary Klein recommends a six-step process to do a premortem:20   \n \n1. Prepare. Participating team members should be relaxed with paper and pen in hand, and should be \nfamiliar with the decision that the group is contemplating. \n \n2. Imagine a fiasco. Klein recommends considering a worst case scenario. He suggests that you should \nconsider the outcome embarrassing and devastating to the point where people on the team are unwilling \nto speak to one another. He then suggests that while this crystal ball is good enough to see the failure, it \nis too shoddy to make out the causes. \n \n3. Generate reasons for the failure. He asks each team member to spend three minutes writing down all \nthe reasons behind the failure. The team members should do this step independently and silently. \n \n4. Consolidate the lists.  After everyone is done, the facilitator goes around the room and asks each team \nmember for one item from his or her list and records it on a white board. The process is not complete \nuntil every item on everyone\u2019s list is captured on the board. This should represent a comprehensive list of \nthe concerns and issues. \n \n5. Revisit the plan. The team is now in a position to revisit the main concerns regarding the prospective \ndecision. If there isn\u2019t sufficient time, the team can arrange another meeting to address ways to tackle \nthe other problems. \n \n6. Periodically review the list. Klein suggests periodically taking out the list in order to keep the specter \nof failure fresh in the minds of the team members.     \n  \nKlein didn\u2019t develop the premortem to help investors, but the utility should be clear. A premortem tempers \noverconfidence, reduces the risk of groupthink, and \u201cunleashes the imagination of knowledgeable individuals in \na much-needed direction.\u201d21   \n   \nSome have criticized the premortem as being too negative or pessimistic. The central value in the process is \ncorrecting the tendency to be overconfident. So, indeed, it may be useful to run through this exercise using \npositive scenarios if your assumption is based on negative scenarios. The value of the task is that it draws on \nthe way our minds work to counterbalance the potentially excessive confidence in our view.      \n    \nMistake #3: Underestimating or underappreciating an opposing point of view. \nSolution: Create a red team to challenge your mind-set. \n \nIt is common for investment firms to position their portfolios to reflect a particular point of view or theme. For \nexample, the leaders of the firm may be bullish or bearish on the overall market, risk-seeking or risk-averse to \nreflect a \u201crisk-on\u201d or \u201crisk-off\u201d environment, or exposed to a theme such as \u201cinterest rates are rising\u201d or \n\u201cinterest rates are falling.\u201d These beliefs, called \u201cmind-sets,\u201d need to be explicit. You can define a mind-set as \n\u201ca series of expectations through which a human sees the world.\u201d22     \n \nMind-sets can be good, of course, when they get everyone on the same page. But mind-sets are a problem if \nthe world changes. As Richards Heuer, who worked in the intelligence office of the Central Intelligence \nAgency (CIA), wrote, \u201cThe disadvantage of a mind-set is that it can color and control our perception to the \nextent that an experienced specialist may be among the last to see what is really happening when events take \n"
    },
    {
      "number": 7,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n7 \na new and unexpected turn. When faced with a major paradigm shift, analysts who know the most about a \nsubject have the most to unlearn.\u201d23    \n \nRed-teaming is a technique to offset the rigidity of mind-sets. The idea is an old one that comes from military \nstrategy. A red team attacks and a blue team defends. In this case, the blue team would be assigned to \ndefend the mind-set that underpins the firm\u2019s portfolio. The red team would be a small number of people \nwithin the analytical team who would be charged with contesting the mind-set. Red-teaming allows for an \nexplicit challenge to the mind-set within the firm, and at a minimum forces the team members to seriously \nconsider an alternative point of view. \n \nThere are some helpful guidelines in setting up a red-team, blue-team exercise. The first is to structure the \ndebate using \u201clinchpin analysis,\u201d which requires multiple steps:24 \n \n1. Identify the main uncertain factors or key drivers (variables) that will determine an outcome. \n \n2. Pinpoint working assumptions (linchpin premises) about how the key drivers will operate. \n \n3. Advance convincing evidence and reasoning to support the linchpin premises. \n \n4. Address any indicators or signposts that would render the linchpin premises unreliable. \n \n5. Ask what dramatic events or triggers could reverse the expected outcomes. \n \nA senior member of the investment team should assign three to four analysts to be on the red team. The \npeople in this group should be diverse and credible and should not be the main advocates for the mind-set. \nOnce the red team has had time to prepare the challenge based on linchpin analysis, the investment team can \nsit together and the red team can present the case against the status quo. As befitting the intellectual tradition \nof the exercise, the goal of the red team is to figure out a way to \u201cdefeat\u201d the blue team.  \n \nOne of the essential ground rules in a red-team, blue-team exercise is to explicitly separate facts from \nopinions. A fact is a piece of information that is presumed to have objective reality. As a consequence, it can \nbe disproved. An opinion is a belief that is stronger than an impression but less strong than positive knowledge. \nAn opinion can be difficult to disprove. Presenters from both sides must be overt about what are facts and \nwhat are opinions. Facts, which themselves can change over time, should rule the day.25    \n \nIf you want to practice discriminating between facts and opinions, pick up a report or memo written by a \nresearch analyst and highlight the facts in one color and the opinions in another color. You might be surprised \nat the relative contributions of each. Decision making in the face of uncertainty is a great challenge, and \nopinion is likely to play a role. But when opinion overshadows fact, it is time to update beliefs.  \n \nThere is substantial evidence showing that once we reach a mind-set, we are not inclined to change our view. \nThis is even in cases where arriving at the mind-set was intellectually difficult. In theory, our beliefs are \nsupposed to be tentative and subject to change upon the arrival of new information. Bayes\u2019s Theorem \nprovides the mathematical way to do this.26  \n \nThe primary barrier to updating beliefs is what psychologists call confirmation bias. This bias says that we are \nmore likely to seek information that confirms our belief than information that disconfirms it. It also says that \nwhen we face ambiguous information, we naturally interpret it in a way that is favorable to our belief. \nConfirmation bias is relevant for military leaders, executives, and investors, among others.27   \n"
    },
    {
      "number": 8,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n8 \nWhereas the outside view or premortem help anticipate scenarios for the future by overcoming overconfidence, \nred-teaming seeks to bend a mind-set that has become too rigid by revealing alternative analyses. Michael \nHandel, formerly a professor at the U.S. Naval War College, wrote: \u201cClearly, the majority of failures to \nanticipate strategic surprise can be correlated with conceptual rigidity and a high incidence of perceptual \ncontinuity.\u201d28 This is true, too, in the worlds of business and investing.   \n \nMistake #4: Not imposing self-accountability. \nSolution: Maintain a decision-making journal.  \n \nOne of the challenges to learning in markets or business is that the environment constantly changes. You can \nanticipate outcomes only with some probability. As a result, sometimes good decisions turn out poorly and bad \ndecisions turn out well. Since our minds are biased to assume that the outcome reflects the level of skill, \nkeeping track of the quality of our decisions is difficult.29 Most investment professionals and businesspeople \ndon\u2019t keep track of how good their decisions were. They keep track of how things turned out as the result of \ntheir decisions. \n \nOver the long haul, of course, good decisions provide a much higher chance of desirable outcomes. But in the \nshort run the link between decisions and results can be very loose. The primary way to focus attention on the \ndecision-making process is to keep a journal that documents your thinking. This is how you impose \naccountability on yourself. \n \nHere\u2019s what you do. Go out and get a notebook. When you are making a consequential decision in your \nportfolio, business, or life, write down what you expect to happen, why you expect it to happen, and attach \nprobabilities to your views. If you are so inclined, also jot down how you feel physically and emotionally. Make \nsure you note the date and time.  \n \nThis practice is valuable because it mitigates some common cognitive traps. The first of these is hindsight bias, \nthe sense that you knew what was going to happen, before the event occurred, with a greater probability than \nyou actually did. Creeping determinism is a related trap. This is the name for the sense that what happened \nwas inevitable. In both cases, your mind draws out the facts around an event that occurs and weaves a \nnarrative to explain the result. You do this unconsciously and effortlessly. Knowledge of the outcome and the \nfacts behind it bleed into your memory, and you start to believe that you knew more than you did. \n \nYour decision-making journal stops this process in its tracks. Because your prior views are stated clearly, you \ncan\u2019t reconstruct your beliefs in a faulty fashion. You also create an opportunity to learn about your own \ntendencies. You can keep score. \n \nWhen maintaining your journal, it is essential to describe your views using specific probabilities. For instance, \nsaying \u201cthere\u2019s a 70 percent chance of rain tomorrow\u201d is a lot better than saying \u201cthere\u2019s a good chance it will \nrain tomorrow.\u201d There are at least two reasons to express your expectations with numerical probabilities. \n \nThe first reason is that language can be very ambiguous. Sherman Kent, the initial director of the CIA Office \nof National Estimates, asked 23 military officers to assign specific probabilities to various statements. For \nexample, some statements, such as \u201calmost certainly,\u201d consistently drew a probability of 80 percent or higher. \nLikewise, \u201cchances are slight\u201d generally meant a probability of 10 percent or less. But some statements had a \nwide range of assigned probabilities. \u201cProbable\u201d evoked a range from 25 to 90 percent. A statement that is so \nvague to its recipients is next to useless.30 \n \n"
    },
    {
      "number": 9,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n9 \nSpecific probabilities in your journal also allow you to keep score. This takes even more discipline, but can \nprovide essential feedback. The Brier score is a classic way to measure the accuracy of probabilistic \nforecasts.31 In its simplest form, a Brier score is the square of the error, where everything is expressed in \npercentages. For example, if you predict that it will rain tomorrow with 100 percent probability and it does, \nthen the Brier score is zero (1.00 \u2013 1)2. A zero Brier score is a perfect forecast. If you predict rain tomorrow \nwith 100 percent probability and it doesn\u2019t rain, then the Brier score is 1.00 (1.00 \u2013 0)2. A Brier score of one \nis the worst possible score. \n \nWe can consider a slightly more complicated case. Say you predict rain with an 80 probability and it rains. \nYour Brier score is 0.04 (0.80 \u2013 1)2. If you predict rain with an 80 percent probability and it doesn\u2019t rain, then \nyour Brier score is 0.64 (0.80 \u2013 0)2. A Brier score is like golf in that the lower the number the better your \nability. \n \nIn forecasting, there are two key measures of accuracy. The first is calibration, which captures how well your \nsubjective probabilities match the objective probabilities over time. To illustrate, if it rains 70 percent of the \ndays when you predict a 70 percent chance of rain, you are well calibrated. This gauges whether you have the \nappropriate humility. \n \nThe second measure is discrimination, which asks whether over the long haul you assign higher probabilities \nto things that actually occur. Lots of forecasts of 100 percent probability before rainy days and zero percent \nprobability before sunny days would demonstrate good discrimination. This measure captures justified \ndecisiveness.32        \n \nCalibration and discrimination tend to be positively correlated, but they can diverge. Consider the simple \nprediction that it rains 50 percent of the days in London. This is close to the actual percentage of days that it \nrains, and hence would be well calibrated over time.  \n \nBut for planning picnics, you need discrimination. High discrimination would be a series of accurate predictions \nof rain where roughly half were zero percent probability and the other half 100 percent probability. In this case, \nboth calibration and discrimination would be high, and the predictions would be very useful.   \n \nBesides their work on heuristics and biases, Kahneman and Tversky are also known for prospect theory. This \ntheory describes how the choices people make depart from normative economic theory when the decisions \nare in probabilistic settings and involve risk. For example, most people are loss averse, which means that they \nsuffer from a loss roughly 2.0 - 2.5 times as much as they enjoy a comparable gain.33  \n \nAfter publishing on prospect theory, Kahneman and Tversky sought to quantify the psychological weights, \ncalled \u201cdecision weights,\u201d which people placed on different types of financial propositions. Exhibit 1 shows the \nresults. Were subjective and objective probabilities to line up in a way consistent with theory, all decisions \nwould land on the line at a 45 degree angle.   \n \n \n \n \n \n \n \n \n \n"
    },
    {
      "number": 10,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n10 \nExhibit 1: Decision Weights versus Objective Probabilities for Financial Propositions \n \nSource: Daniel Kahneman, Thinking, Fast and Slow (New York: Farrar, Straus and Giroux, 2011), 315.  \n \nIn general, subjects offer accurate weights at the far extremes but have trouble in between. For instance, they \ntend to overweight low-probability events. Imagine you have a 1 percent chance of winning $1 million, and \nyou\u2019ll know the outcome tomorrow. You have some hope, but it is slim. Subjects place a decision weight of \n5.5 percent on a 1 percent objective probability. Kahneman calls this the \u201cpossibility effect.\u201d \n \nSubjects also tend to underweight high probability events. Now let\u2019s say you have a 1 percent chance of not \nwinning the $1 million. Subjects assign a decision weight of 91.2 percent on a 99 percent objective probability. \nAnxiety over the possibility of losing is more salient than the hope of winning. Kahneman calls this the \n\u201ccertainty effect.\u201d These patterns in decision weights can be highly relevant in setting probabilities, especially \nnear the extremes.34   \n \nA journal that chronicles your decisions allows you to get honest feedback about your thoughts and provides \nvaluable material to help sharpen your forecasts. Our best advice is to be disciplined in maintaining your journal, \nto document your views in probabilities, and to periodically review your predictions and score yourself. Note \nthe essential distinction between calibration and discrimination.  \n \nMistake #5: Creating an environment that is not conducive to good decisions. \nSolution: Be mindful of your surroundings and work to improve them.  \n \nOne idea that is well established in social psychology is the fundamental attribution error, or correspondence \nbias. This idea says that when we observe the behavior of others, we attribute that behavior to the individual\u2019s \ndisposition and not to the situation. As important, there is substantial evidence that shows that the situation \nexerts a very powerful influence on the decisions that people make.  \n \nThe Stanford Prison Experiment, conducted by a psychologist named Philip Zimbardo in the summer of 1971, \nis one of the most chilling experimental demonstrations of this point. Zimbardo converted part of the building \nhousing the psychology department at Stanford University into a prison. He then found 24 physically and \n0%\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n100%\n0%\n20%\n40%\n60%\n80%\n100%\nObjective Probability\nSubjective Probability\n"
    },
    {
      "number": 11,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n11 \nmentally healthy male subjects to participate in the study. With the toss of a coin, he randomly assigned half of \nthem to be \u201cprisoners\u201d and the other half \u201cguards.\u201d Zimbardo assumed the role of \u201csuperintendent.\u201d35 \n    \nWith the help of the Palo Alto police, the prisoners were arrested and subsequently de-humanized and de-\nindividualized. The guards were free, within limits, to do whatever they deemed necessary to maintain law and \norder. Only a few days into the planned two-week duration, Zimbardo had to call off the experiment. The \nprisoners had become depressed and showed signs of extreme stress, and the guards had become sadistic. \n \nZimbardo provides a day-by-day account of the events in his book, The Lucifer Effect.36 While his experiment \nis an extreme example of this phenomenon, Zimbardo notes that the same conditions were in place for other \ncases of bad behavior, including the abuse of prisoners at Abu Ghraib, Iraq, in 2003 and 2004. In the \nappendix, we summarize some of Zimbardo\u2019s recommendations for resisting the sway of bad social influences.  \n \nMost organizations don\u2019t find themselves in situations as extreme as the Stanford Prison Experiment, but the \nmistake of creating an environment that is less than ideal for quality decision making is prevalent nonetheless. \nOne of the essential lessons from the fundamental attribution bias is that social context plays a major role in \nshaping decisions, and we tend to underestimate that role. \n \nThe first step in creating an environment favorable to good decisions is to audit the congruence between your \nstated process and your actual behavior. There are lots of processes that may lead to attractive portfolio \nresults, from certain strategies that rely on rapid trading to low turnover of highly concentrated portfolios. But \nmany firms stray from the essence of their process as the result of external pressure.  \n \nFor example, some investment firms that claim to have a long-term orientation focus disproportionately on the \nshort term following a spell of poor results. Others claim to use a fundamental approach yet use charts to time \ntrades. It is essential to align what you say you do with what you actually do. This is where checklists can act \nas guardrails to keep the organization consistent and true to its principles.   \n \nLeaders of investment organizations must be particularly attuned to the environment they create. The role of \nstress is a good example. Some stress is good, of course, as it activates the body and mind and encourages \nfocus. But too much stress is bad and causes the quality of decisions to deteriorate rapidly.37     \n \nRobert Sapolsky, a professor of biological sciences at Stanford University, is one of the world\u2019s foremost \nresearchers on stress.38 He suggests that for most of the animal world, stressors are generally physical: \nYou\u2019re a zebra who becomes a lion\u2019s target for lunch. In those cases, the stress response kicks in and it\u2019s \nfight-or-flight. But once the emergency has passed, the body returns to its normal state. The stress response \nis extreme but short-lived. \n \nHumans face physical stressors from time to time as well. But most of our stressors are psychological, \nincluding dealing with relationships, the big speech next week, and deadlines on the job. What is essential is \nthat our bodies don\u2019t distinguish between physical and psychological stressors. We have the same reactions. \nChronic psychological stress puts your body in a constant state of emergency.  \n \nTo focus on the present, the stress response turns on short-term systems and turns off long-term systems. \nThese include the digestive, immune, and reproductive systems. There\u2019s no use allocating resources to digest \nlunch or fend off disease if you are not long for this world. As a result, symptoms of chronic stress include \nulcers, a higher likelihood of getting sick, and reproductive problems.  \n \n"
    },
    {
      "number": 12,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n12 \nHere\u2019s the essential link back to investment management: Stress creates a focus on the short-term and \nmakes long-term thinking next to impossible. This makes enormous sense from an evolutionary point of view. \nAfter all, the stress response evolved to help you elude danger. But it can be devastating to an organization \nthat seeks to make investments that take years to pay off.  \n \nMost are familiar with the formula for reducing stress, which is easier said than done. Items include eating well, \nsleeping sufficiently, exercising frequently, and maintaining social connections (family, friends, and religious \ngatherings). Good leaders of investment organizations have an even keel. They don\u2019t get too excited when \nresults are good or too despondent when results are challenging.  \n \nIf you lead an investment team, you may want to evaluate the environment you have created across a few \ndimensions. Ask these questions: \n \n1. Does the analytical team have access to, and avail themselves of, base rate data so as to properly use \nthe outside view? \n \n2. As an organization, are we open to new ideas that may challenge our mind-sets? Do we need to do a \nred-term exercise to confront our beliefs? \n \n3. Are we always explicit about distinguishing between facts and opinions? Are we properly weighting the \ntwo? \n \n4. Are we structured so that we can keep track of the quality of our decisions\u2014our process\u2014as well as our \noutcomes? Are we communicating using probabilities instead of statements? How good are we at \nproviding feedback? \n \n5. Do we have the correct amount of stress in our organization? Have we had episodes where we\u2019ve veered \ntoward too much stress, hence affecting our decisions? \n \nSummary \n \nNo investment organization is perfect, and almost all seek to improve. There are a couple of paths to \nimprovement. One is to get smarter and the other is to be less stupid. This report covered five common \nmistakes that investment firms make and offered practical guidance on how to cope with each of them. Each \nsolution relies not on getting smarter but rather on fending off poor practices that you can fix. \n \n"
    },
    {
      "number": 13,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n13 \nEndnotes \n \n1 Phil Birnbaum, \u201cEliminating Stupidity Is Easier than Creating Brilliance,\u201d Sabermetric Research Blog, June 13, \n2013. See http://blog.philbirnbaum.com/2013/06/eliminating-stupidity-is-easier-than.html. \n2 Atul Gawande, The Checklist Manifesto: How to Get Things Right (New York: Metropolitan Books, 2009), \n168. \n3 Charles D. Ellis, \u201cThe Loser\u2019s Game,\u201d Financial Analysts Journal, Vol. 31, No. 4, July-August 1975,19-26. \n4 Simon Ramo, Extraordinary Tennis for the Ordinary Player (New York: Crown Publishers, 1973), 22. \n5 Ellis quotes Admiral Samuel Eliot Morison, who said, \u201cIn warfare, mistakes are inevitable. Military decisions \nare based on estimates of the enemy\u2019s strengths and intentions that are usually faulty, and on intelligence that \nis never complete and often misleading. Other things being equal, the side that makes the fewest strategic \nerrors wins the war.\u201d Tommy Armour, a professional golfer, wrote, \u201cThe best way to win is by making fewer \nbad shots.\u201d \n6 Roger Buehler, Dale Griffin, and Michael Ross, \u201cInside the Planning Fallacy: The Causes and Consequences \nof Optimistic Time Predictions,\u201d in Thomas Gilovich, Dale Griffin, and Daniel Kahneman, eds., Heuristics and \nBiases: The Psychology of Intuitive Judgment (Cambridge, UK: Cambridge University Press, 2002), 250-270. \n7 Bent Flyvbjerg, \u201cTruth and Lies about Megaprojects,\u201d Speech at Delft University of Technology, September \n26, 2007. \n8 Daniel Kahneman, Thinking, Fast and Slow (New York: Farrar, Straus and Giroux, 2011), 245-254. Also, \nDan Lovallo and Daniel Kahneman, \u201cDelusions of Success,\u201d Harvard Business Review, July 2003, 56-63.    \n9 Dan Lovallo, Carmina Clarke, and Colin Camerer, \u201cRobust Analogizing and the Outside View: Two Empirical \nTests of Case-Based Decision Making,\u201d Strategic Management Journal, Vol. 33, No. 5 May 2012, 496-512. \n10 Don Moore and Paul J. Healy, \u201cThe Trouble with Overconfidence,\u201d Psychological Review, Vol. 115, No. 2, \nApril 2008, 502-517. \n11 This section is based on Michael J. Mauboussin, Think Twice: Harnessing the Power of Counterintuition \n(Boston, MA: Harvard Business Review Press, 2011), 13-16. \n12 Michael J. Mauboussin, Dan Callahan, Bryant Matthews, and David A. Holland, \u201cHow to Model Reversion to \nthe Mean: Determining How Fast, and to What Mean, Results Revert,\u201d Credit Suisse Global Financial \nStrategies, September 17, 2013, 11.  \n13 Lovallo, Clarke, and Camerer.  \n14 Phil Rosenzweig, Left Brain, Right Stuff: How Leaders Make Winning Decisions (New York: PublicAffairs, \n2014), 112-118. \n15 Evan Heit, \u201cFeatures of Similarity and Category-Based Induction,\u201d Proceedings of the Interdisciplinary \nWorkshop on Similarity and Categorization, 1997, 115-121.  \n16 Amos Tversky, \u201cFeatures of Similarity,\u201d Psychological Review, Vol. 84, 1977, 327-352. Reprinted in Eldar \nShafir, ed. Preference, Belief, and Similarity: Selected Writings, Amos Tversky (Cambridge, MA: MIT Press, \n2004). \n17 Paul R. Carlile and Clayton M. Christensen, \u201cThe Cycles of Theory Building in Management Research,\u201d \nHarvard Business School Working Paper Series, No. 05-057, 2005. Also, see the chapter, \u201cHistory, The \nFickle Teacher,\u201d in Duncan J. Watts, Everything Is Obvious*:*Once You Know the Answer (New York: Crown \nBusiness, 2011), 108-134. \n18 Deborah J. Mitchell, J. Edward Russo, and Nancy Pennington, \u201cBack to the Future: Temporal Perspective \nin the Explanation of Events,\u201d Journal of Behavioral Decision Making, Vol. 2, No. 1, January/March 1989, \n25-38.  \n19 J. Edward Russo and Paul J. H. Schoemaker, Winning Decisions: Getting it Right the First Time (New \nYork: Currency, 2002), 111-112. There is also a clear discussion of this concept in Chip Heath and Dan \nHeath, Decisive: How to Make Better Choices in Life and Work (New York: Crown Business, 2013), 201-\n203. \n"
    },
    {
      "number": 14,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n14 \n20 Gary Klein, Intuition at Work: Why Developing Your Gut Instincts Will Make You Better at What You Do \n(New York: Currency, 2003), 88-91. Also, Gary Klein, \u201cPerforming a Project Premortem,\u201d Harvard Business \nReview, September 2007, 18-19. \n21 Kahneman, 265. \n22 Roger Z. George, \u201cFixing the Problem of Analytical Mind-Sets: Alternative Analysis,\u201d International Journal of \nIntelligence and Counterintelligence, Vol. 17, No. 3, 2004, 385-404.  \n23 Richards J. Heuer, Jr., Psychology of Intelligence Analysis (Washington, D.C: Center for the Study of \nIntelligence, 1999), 5. \n24 George, 391.  \n25 Sam Arbesman argues that facts have a half-life, which differs by field. Awareness of how rapidly facts can \nchange is very useful. See Samuel Arbesman, The Half-life of Facts: Why Everything We Know Has an \nExpiration Date (New York: Current, 2012). \n26 James V Stone, Bayes\u2019 Rule: A Tutorial Introduction to Bayesian Analysis (Sebtel Press, 2013). \n27 Chetan Dave and Katherine W. Wolfe, \u201cOn Confirmation Bias and Deviations From Bayesian Updating,\u201d \nWorking Paper, March 21, 2003.  \n28 Michael I. Handel, War, Strategy, and Intelligence (New York: Frank Cass and Company, 1989), 270. \n29 Michael J. Mauboussin and Dan Callahan, \u201cOutcome Bias and the Interpreter: How Our Minds Confuse Skill \nand Luck,\u201d Credit Suisse Global Financial Strategies, October 15, 2013.  \n30 Heuer, 155. \n31 Glenn W. Brier, \u201cVerification of Forecasts Expressed in Terms of Probability,\u201d Monthly Weather Review, Vol. \n78, No. 1, January 1950, 1-3.  \n32 Philip E. Tetlock, Expert Political Judgment: How Good Is It? How Can We Know? (Princeton, NJ: \nPrinceton University Press, 2005) 51-54.  \n33 Daniel Kahneman and Amos Tversky, \u201cProspect Theory: An Analysis of Decision under Risk,\u201d \nEconometrica, Vol. 47, No. 2, March 1979, 263-291.  \n34 Kahneman, 314-316. \n35 See http://www.prisonexp.org/. \n36 Philip Zimbardo, The Lucifer Effect: Understanding How Good People Turn Evil (New York: Random \nHouse, 2007). \n37 John Coates, The Hour Between Dog and Wolf: Risk Taking, Gut Feelings, and the Biology of Boom and \nBust (New York: The Penguin Press, 2012).  \n38 Robert Sapolsky, Why Zebras Don\u2019t Get Ulcers: A Guide to Stress, Stress-Related Disease, and Coping \n(New York: W.H. Freeman & Co., 1994). \n39 http://www.lucifereffect.com/guide_tenstep.htm. \n \n \n \n"
    },
    {
      "number": 15,
      "text": " \n \nFebruary 24, 2014 \n \nMethods to Improve Decisions \n15 \nAppendix \n \nZimbardo\u2019s Ten-Step Program to Build Resistance and Resilience39 \n \nPhilip Zimbardo provides ten steps to help resist undesirable social influence. The steps also promote \nresilience and civic virtue. \n \n1. Admit your mistakes, say you\u2019re sorry, and if appropriate ask for forgiveness. Failure to admit mistakes \ncan compound problems. \n \n2. Be mindful by being in the moment and heed situational clues. Pay attention to the things you do \nautomatically and ask whether they make sense.  \n \n3. Take responsibility for your actions. Diffusion of responsibility can allow unwelcome social influence to \ntake root.  \n \n4. Maintain your individuality by making sure no one places you into a category. Anonymity can conceal \nwrongdoing and undermines human connection.  \n \n5. Respect just authority and rebel against unjust authority. Sort the real leaders who deserve respect from \nthe false leaders who claim authority without substance.  \n \n6. Balance group acceptance and independence. We are social animals and enjoy the comfort of the group. \nBut sometimes conformity is bad for the social good. Never sacrifice personal beliefs or standards to \nconform to the group.  \n \n7. Pay attention to how others frame ideas and be \u201cframe vigilant.\u201d Be aware of how words or the \npresentation of concepts shape your decisions. As Zimbardo writes, he \u201cwho makes the frame becomes \nthe artist, or the con artist.\u201d \n \n8. Consider the past and the future when dealing with the present. Adopting the outside view can help you \nwith incorporating the past, and premortems and analysis of costs and benefits can help with the future.  \n \n9. Try not to sacrifice personal freedom for the illusion of security. The sacrifices tend to be real in the \npresent but the security is illusory in the future. \n \n10. Oppose unjust systems when you identify them as such. These include cults, gangs, families, and even \ncorporations.   \n"
    },
    {
      "number": 16,
      "text": " \n \n \nGeneral disclaimer / Important information  \nThis document was produced by and the opinions expressed are those of Credit Suisse as of the date of writing and are subject to change. It has \nbeen prepared solely for information purposes and for the use of the recipient. It does not constitute an offer or an invitation by or on behalf of \nCredit Suisse to any person to buy or sell any security. Nothing in this material constitutes investment, legal, accounting or tax advice, or a \nrepresentation that any investment or strategy is suitable or appropriate to your individual circumstances, or otherwise constitutes a personal \nrecommendation to you. The price and value of investments mentioned and any income that might accrue may fluctuate and may fall or rise. Any \nreference to past performance is not a guide to the future.  \nThe information and analysis contained in this publication have been compiled or arrived at from sources believed to be reliable but Credit Suisse \ndoes not make any representation as to their accuracy or completeness and does not accept liability for any loss arising from the use hereof. A \nCredit Suisse Group company may have acted upon the information and analysis contained in this publication before being made available to \nclients of Credit Suisse. Investments in emerging markets are speculative and considerably more volatile than investments in established markets. \nSome of the main risks are political risks, economic risks, credit risks, currency risks and market risks. Investments in foreign currencies are subject \nto exchange rate fluctuations. Before entering into any transaction, you should consider the suitability of the transaction to your particular \ncircumstances and independently review (with your professional advisers as necessary) the specific financial risks as well as legal, regulatory, \ncredit, tax and accounting consequences. This document is issued and distributed in the United States by Credit Suisse Securities (USA) LLC, a \nU.S. registered broker-dealer; in Canada by Credit Suisse Securities (Canada), Inc.; and in Brazil by Banco de Investimentos Credit Suisse (Brasil) \nS.A.  \nThis document is distributed in Switzerland by Credit Suisse AG, a Swiss bank. Credit Suisse is authorized and regulated by the Swiss Financial \nMarket Supervisory Authority (FINMA). This document is issued and distributed in Europe (except Switzerland) by Credit Suisse (UK) Limited and \nCredit Suisse Securities (Europe) Limited, London. Credit Suisse Securities (Europe) Limited, London and Credit Suisse (UK) Limited, authorised \nby the Prudential Regulation Authority (PRA) and regulated by the Financial Conduct Authority (FCA) and PRA, are associated but independent \nlegal and regulated entities within Credit Suisse. The protections made available by the UK\u2018s Financial Services Authority for private customers do \nnot apply to investments or services provided by a person outside the UK, nor will the Financial Services Compensation Scheme be available if the \nissuer of the investment fails to meet its obligations. This document is distributed in Guernsey by Credit Suisse (Guernsey) Limited, an independent \nlegal entity registered in Guernsey under 15197, with its registered address at Helvetia Court, Les Echelons, South Esplanade, St Peter Port, \nGuernsey. Credit Suisse (Guernsey) Limited is wholly owned by Credit Suisse and is regulated by the Guernsey Financial Services Commission. \nCopies of the latest audited accounts are available on request. This document is distributed in Jersey by Credit Suisse (Guernsey) Limited, Jersey \nBranch, which is regulated by the Jersey Financial Services Commission. The business address of Credit Suisse (Guernsey) Limited, Jersey \nBranch, in Jersey is: TradeWind House, 22 Esplanade, St Helier, Jersey JE2 3QA. This document has been issued in Asia-Pacific by whichever of \nthe following is the appropriately authorised entity of the relevant jurisdiction: in Hong Kong by Credit Suisse (Hong Kong) Limited, a corporation \nlicensed with the Hong Kong Securities and Futures Commission or Credit Suisse Hong Kong branch, an Authorized Institution regulated by the \nHong Kong Monetary Authority and a Registered Institution regulated by the Securities and Futures Ordinance (Chapter 571 of the Laws of Hong \nKong); in Japan by Credit Suisse Securities (Japan) Limited; elsewhere in Asia/Pacific by whichever of the following is the appropriately authorized \nentity in the relevant jurisdiction: Credit Suisse Equities (Australia) Limited, Credit Suisse Securities (Thailand) Limited, Credit Suisse Securities \n(Malaysia) Sdn Bhd, Credit Suisse AG,Singapore Branch,and elsewhere in the world by the relevant authorized affiliate of the above.  \nThis document may not be reproduced either in whole, or in part, without the written permission of the authors and CREDIT SUISSE.  \n\u00a9 2014 CREDIT SUISSE GROUP AG and/or its affiliates. All rights reserved \n  \n"
    }
  ]
}